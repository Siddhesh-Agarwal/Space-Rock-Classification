{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell the machine what folder contains the image data\n",
    "data_dir = \"./Data\"\n",
    "\n",
    "# Read the data, crop and resize the images, split data into two groups: test and train\n",
    "def load_split_train_test(data_dir, valid_size=0.2):\n",
    "\n",
    "    # Transform the images to train the model\n",
    "    train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Transform the images to test the model\n",
    "    test_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create two variables for the folders with the training and testing images\n",
    "    train_data = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "\n",
    "    # Get the number of images in the training folder\n",
    "    num_train = len(train_data)\n",
    "\n",
    "    # Create a list of numbers from 0 to the number of training images - 1\n",
    "    # Example: For 10 images, the variable is the list [0,1,2,3,4,5,6,7,8,9]\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    # If valid_size is .2, find the index of the image that represents 20% of the data\n",
    "    # If there are 10 images, a split would result in 2\n",
    "    # split = int(np.floor(.2 * 10)) -> int(np.floor(2)) -> int(2) -> 2\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    # Randomly shuffle the indices\n",
    "    # For 10 images, an example would be that indices is now the list [2,5,4,6,7,1,3,0,9,8]\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # With the indices randomly shuffled,\n",
    "    # grab the first 20% of the shuffled indices, and store them in the training index list\n",
    "    # grab the remainder of the shuffled indices, and store them in the testing index list\n",
    "    # Given our example so far, this would result is:\n",
    "    # train_idx is the list [1,5]\n",
    "    # test_idx is the list [4,6,7,1,3,0,9,8]\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # Create samplers to randomly grab items from the training and testing indices lists\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    # Create loaders to load 16 images from the train and test data folders\n",
    "    # Images are chosen based on the shuffled index lists and by using the samplers\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=16\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_data, sampler=test_sampler, batch_size=16\n",
    "    )\n",
    "\n",
    "    # Return the loaders so you can grab images randomly from the training and testing data folders\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function that shuffles images,\n",
    "# create a trainloader to load 20% of the images\n",
    "# create a testloader to load 80% of the images\n",
    "trainloader, testloader = load_split_train_test(data_dir, 0.2)\n",
    "\n",
    "# Print the type of rocks that are included in the trainloader\n",
    "print(trainloader.dataset.classes)\n",
    "\n",
    "# Transform an image into pixels and resize it\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Randomly select a set of images by using a similar approach as the load_split_train_test function\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "\n",
    "    # Create an iterator to iterate over the shuffled images in the test image dataset\n",
    "    dataiter = iter(loader)\n",
    "\n",
    "    # Get and return the images and labels from the iterator\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Show five images - you can change this number\n",
    "images, labels = get_random_images(5)\n",
    "\n",
    "# Convert the array of pixels to an image\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Get a list of all classes in the training data\n",
    "classes = trainloader.dataset.classes\n",
    "\n",
    "# Draw the images in a plot to display in the notebook\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplot(1, len(images), ii + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "\n",
    "# Display all of the images\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if you're using a CPU or a GPU device to build the deep learning network\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all the neurons\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Wire the neurons together to create the neural network\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "\n",
    "# Add the neural network to the device\n",
    "model.to(device)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial number of iterations to search for associations\n",
    "epochs = 5\n",
    "print_every = 5\n",
    "\n",
    "# Initialize the loss variables\n",
    "running_loss = 0\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "# Track the current training step, start at 0\n",
    "steps = 0\n",
    "\n",
    "# Search for associations in the features\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Count each epoch\n",
    "    epoch += 1\n",
    "\n",
    "    # Load in all of the image inputs and labels from the TRAIN loader \n",
    "    for inputs, labels in trainloader:\n",
    "\n",
    "        # Count each training step\n",
    "        steps += 1\n",
    "        print('Training step ', steps)\n",
    "\n",
    "        # Load the inputs and labels to the already selected device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero out gradients to avoid accumulations of gradiants across training iterations\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass the images through the model, return the log probabilities of each label\n",
    "        logps = model.forward(inputs)\n",
    "\n",
    "        # Run the log probabilities through the criterion to get the output graph\n",
    "        loss = criterion(logps, labels)\n",
    "\n",
    "        # Use the loss graph to compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters based on the current gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the actual loss number to the running loss total\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Every 5 steps, evaluate the model\n",
    "        if steps % print_every == 0:\n",
    "\n",
    "            # Initialize loss and accuracy\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Start the model evaluation\n",
    "            model.eval()\n",
    "\n",
    "            # Refine the accuracy of the prediction without updating the gradients\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # Load in all of the image inputs and labels from the TEST loader \n",
    "                for inputs, labels in testloader:\n",
    "\n",
    "                    # Load the inputs and labels to the already selected device\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    # Pass the images through the model, return the log probabilities of each label\n",
    "                    logps = model.forward(inputs)\n",
    "\n",
    "                    # Run the log probabilities through the criterion to get the output graph\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "\n",
    "                    # Add the actual loss number to the running loss total for the test batch\n",
    "                    test_loss += batch_loss.item()\n",
    "\n",
    "                    # Return a new tensor with the true probabilities\n",
    "                    ps = torch.exp(logps)\n",
    "\n",
    "                    # Return the largest probability and class of the new tensor along a given dimension\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "                    # Reshape the tensor to match the same shape as the top class\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "                    # Compute the accuracy and add it to the running accuracy count for the test batch\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            # Append the training and testing losses\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))  \n",
    "\n",
    "            # Display the accuracy of the prediction with 3 digits in the fractional part of the decimal\n",
    "            print(f\"     Epoch {epoch}/{epochs}: \"\n",
    "                f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                f\"Test accuracy: {accuracy/len(testloader):.3f}\\n\")\n",
    "\n",
    "            # Train the model\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "            # After 5 training steps, start the next epoch\n",
    "            # Break here in case the trainloader has remaining data\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get five random images and display them in a figure with their labels\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels = get_random_images(5)\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "\n",
    "# Load all of the classes from the training loader\n",
    "classes=trainloader.dataset.classes\n",
    "\n",
    "# Loop through the 5 randomly selected images\n",
    "for ii in range(len(images)):\n",
    "\n",
    "    # Predict the class of each image\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "\n",
    "    # Add the class to the plot graph to display beneath the image\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "    sub.set_title(str(classes[index]) + \":\" + str(res))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "# Reshow the plot with the predicted labels beneath the images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "images, labels = get_random_images(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f768c65be6fae2aaf087dd7c5b38d95e34531cf4e98556994019599475df2fa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
